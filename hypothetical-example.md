# Hypothetical example



â€¦a hypothetical example.

----

Let's assume that you are the manager of a plant that uses 100 gallons of pink paint every month for production.  You pay $10 a gallon for paint, but your vendor makes a proposal: you can instead buy white paint and red paint for $8 a gallon, and blend the two into pink paint.  You would save $200 per month.

But there would be costs from the change.  Additional time, labor, training and equipment.  You have an intern look into it, and it turns out that those cost add up to $100 per month.

However, there is an chance that something could go wrong with using two colors of paint blended together as part of the production process.  The added complexity could potentially cause a non-conformance of the product, requiring reworks (if caught in-house) or replacements (if found by the customer).  All of which can be reduced to a cost.

Your intern calculates that should the two-color process cause a non-conformance, it would cost $200 to remedy.  In any month without a non-conformance you'd still save $100 with the two-color process, but in a month with a non-conformance (we'll assume there's never more than one), you'll lose $100 by using the two-color process.

What you need to know, is the likelihood of a non-conformance.  If it's less than 50% per month, then you should use the two-color process.  If it's more than 50% per month, you should not use the two-color process.

So, you hand the problem over to an academic researcher to whom you've given data in the past.  She passes it on to a PhD candidate, and a year later you get your answer.

The researchers have gathered a lot of data, and run a regression analysis on it.  The candidate tells you that, &ldquo;We are 99-percent confident that using two colors of paint instead of only one will increase the probability of non-conformance in your product.&rdquo;

And after a long pause, you say, &ldquo;Yes, but by how much?&rdquo;

&ldquo;The increase will be greater than zero percent,&rdquo; says the candidate.  &ldquo;We are 99-percent sure of it.&rdquo;

After another long pause, you say, &ldquo;Can you do any better than that?&rdquo;

And the candidate laughs.  &ldquo;Better than 99-percent?  Oh no, I don't think so.  That's a very significant result!&rdquo;

----

This is a cartoonish example, but it illustrates a real problem: real-world managers don't get the answers they need from management research.  Because, while the PhD candidate in the scenario was probably correct that the result of their analysis was &ldquo;very significant&rdquo; from a statistical point of view, that same result was of no use at all to you as a manager trying to make a specific decision.

If it had been unclear whether or not the two-color paint process would increase the probability of non-conformance, then a result of &ldquo;greater than zero percent&rdquo; might have been a valuable insight.  But the questions facing managers of businesses are rarely about whether or not an effect exists.  What managers need to know is the strength of the effect, so they can balance it against other effects when making their decisions.

This is why managers and researchers in management should be wary of null-hypothesis significance testing.  NHST only looks for non-null effects, for effects with a magnitude greater than zero.  What it doesn't do is distinguish very well between effects with minor or major influences on outcomes.

So, empirical studies that use regression analysis can find statistically significant correlations that have large, important effects on outcomes; and they can find statistically significant correlations that have tiny, trivial effects on outcomes; and they can also find statistically significant correlations at everything level of importance between those two.  The statistical significance of a result in no way assures that it is an important one.

Which is, like much of statistics, completely counterintuitive.  How can a result be both &ldquo;significant&rdquo; and &ldquo;trivial&rdquo;?  The rest of this paper will hopefully explain that, and therefore give some insight into how to critically evaluate empirical research, and how to decide if the &ldquo;significant&rdquo; result reported in that research is an important effect, or merely a trivial factoid.



